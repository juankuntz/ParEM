{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ParticleEM/ParEM_neural_latent_variable_model/blob/master/notebooks/CelebA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceG5fAENPfr6"
   },
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TLCqb7XBKj2b"
   },
   "outputs": [],
   "source": [
    "# Install missing modules\n",
    "%%capture\n",
    "!pip install torchtyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UpxVMzKzQGaN"
   },
   "outputs": [],
   "source": [
    "# Import standard modules\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "#from pathlib import Path\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X55L4TEtl385"
   },
   "outputs": [],
   "source": [
    "# Import custom modules\n",
    "!rm -rf ParEM_neural_latent_variable_model\n",
    "!git clone https://github.com/ParticleEM/ParEM_neural_latent_variable_model.git\n",
    "sys.path.append(\"/content/ParEM_neural_latent_variable_model/\")\n",
    "from parem.model import G\n",
    "from parem.pga import PGA\n",
    "from parem.dataset_loaders import get_celeba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3S7vBXKyCtX3"
   },
   "source": [
    "# Set config variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ssu1R-nnaGpW"
   },
   "outputs": [],
   "source": [
    "# Declare dicitonary-like object for storing config variables:\n",
    "args = argparse.Namespace()\n",
    "\n",
    "# Data setttings\n",
    "args.n_images = 40000  # M: training set size \n",
    "\n",
    "# Training settings\n",
    "args.n_batch = 128 # M_b: batch size for theta updates\n",
    "args.n_epochs = 30 # n_epochs = K * M_b / M where K = total number of iterations\n",
    "args.seed = 1 # Seed for PRNG\n",
    "# Device on which to carry out computations:\n",
    "args.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Model Settings\n",
    "args.x_dim = 64  # d_x: dimension of latent space\n",
    "args.likelihood_var = 0.3 ** 2  # sigma^2\n",
    "\n",
    "# PGA Settings\n",
    "args.h = 1e-4 # h: step size \n",
    "args.lambd = 1e-3 / (args.h * args.n_images)  # lambda\n",
    "args.n_particles = 10 # N: number of particles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tbrwaBFyRb4P"
   },
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "aXOewTu5Piuw"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from pathlib import Path\n",
    "drive.mount(\"/content/gdrive\", force_remount=False)\n",
    "GDRIVE_CELEBA_PATH = Path(\"/content/gdrive/MyDrive/celeba/celeba\", force_remount=False)\n",
    "LOCAL_CELEBA_DIR_PATH = Path(\"/content/\") / \"celeba\"\n",
    "assert GDRIVE_CELEBA_PATH.is_dir()\n",
    "if not LOCAL_CELEBA_DIR_PATH.is_dir():\n",
    "  !cp -r $GDRIVE_CELEBA_PATH -d /content/\n",
    "  img_aligned_zip_path = LOCAL_CELEBA_DIR_PATH / \"img_align_celeba.zip\"\n",
    "  !unzip $img_aligned_zip_path -d $LOCAL_CELEBA_DIR_PATH\n",
    "\n",
    "dataset = get_celeba(LOCAL_CELEBA_DIR_PATH / \"img_align_celeba\", args.n_images)  # Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDZ3YFSSF5zK"
   },
   "source": [
    "# Define and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "colab": {
     "background_save": true
    },
    "id": "weq8_THjRHw-"
   },
   "outputs": [],
   "source": [
    "# Define model:\n",
    "model = G(args.x_dim, sigma2=args.likelihood_var, nc=3).to(args.device)\n",
    "\n",
    "# Define training algorithm:\n",
    "pga = PGA(model, dataset, args.h, args.lambd, args.n_particles)\n",
    "\n",
    "# Split dataset into batches for training:\n",
    "training_batches = torch.utils.data.DataLoader(dataset, batch_size=args.n_batch, \n",
    "                                               shuffle=True, pin_memory=True)\n",
    "\n",
    "# Train:\n",
    "losses = []\n",
    "for epoch in range(args.n_epochs):\n",
    "  # model.train()\n",
    "  avg_loss = 0\n",
    "  for imgs, idx in training_batches:\n",
    "      loss = pga.step(imgs.to(device=args.device), idx)\n",
    "      avg_loss += loss\n",
    "      print(\".\", end='')\n",
    "  avg_loss = avg_loss / len(training_batches) \n",
    "  losses.append(avg_loss)\n",
    "  print(f\"Epoch {epoch}: Loss {avg_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oKN0IuLupvF"
   },
   "source": [
    "# Show particle cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "background_save": true
    },
    "id": "N2uiBWF1KPSu"
   },
   "outputs": [],
   "source": [
    "#@title Load auxiliary functions\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "to_range_0_1 = lambda x: (x + 1.) / 2.\n",
    "\n",
    "def show(imgs):\n",
    "    if not isinstance(imgs, list):\n",
    "        imgs = [imgs]\n",
    "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False, dpi=400)\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axs[0, i].imshow(np.asarray(img))\n",
    "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "0aDBWR0Auv0s"
   },
   "outputs": [],
   "source": [
    "model.eval()  # Turn on evaluation mode\n",
    "i = 0  # Image index\n",
    "\n",
    "with torch.no_grad():\n",
    "  torch.random.manual_seed(1)\n",
    "  original_img = to_range_0_1(dataset[i][0].unsqueeze(0))\n",
    "  particle_img = to_range_0_1(model(pga._particles[i, :].to(args.device))).to(original_img.device)\n",
    "  grid = make_grid(torch.concat([original_img, particle_img], dim=0))\n",
    "  show(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGf5tlEluk-Y"
   },
   "source": [
    "## Generate synthetic samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "V-rUPIRqugao"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  n_cols = 8\n",
    "  n_rows = 8\n",
    "  mean = torch.mean(pga._particles, [0, 1, 3, 4])\n",
    "  cov = torch.cov(pga._particles.flatten(0,1).flatten(1, 3).transpose(0, 1))\n",
    "  normal_approx = torch.distributions.multivariate_normal.MultivariateNormal(loc = mean, covariance_matrix=cov)\n",
    "  z = normal_approx.sample(sample_shape=torch.Size([n_cols * n_rows])).unsqueeze(-1).unsqueeze(-1)\n",
    "  samples = to_range_0_1(model(z.to(args.device)))\n",
    "  grid = make_grid(samples)\n",
    "  fig = show(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inHFOXauvFAM"
   },
   "source": [
    "## Inpainting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "bF59nI7COLIO"
   },
   "outputs": [],
   "source": [
    "n_missing_img = 10\n",
    "missing_imgs = torch.stack(dataset[:n_missing_img][0], dim=0)\n",
    "init_x = normal_approx.sample(sample_shape=torch.Size([n_missing_img])).unsqueeze(-1).unsqueeze(-1).requires_grad_(True)\n",
    "opt = torch.optim.Adam([init_x], 1e-2)\n",
    "mse = torch.nn.MSELoss()\n",
    "missing_mask = torch.zeros_like(missing_imgs, dtype=torch.bool)\n",
    "\n",
    "for i in range(10, 22):\n",
    "  for j in range(10, 22):\n",
    "        missing_mask[..., i, j] = True\n",
    "\n",
    "for i in range(1000):\n",
    "  opt.zero_grad()\n",
    "  filled_imgs = model.forward(init_x.to(args.device)).to('cpu')\n",
    "  loss = mse(filled_imgs[~missing_mask], missing_imgs[~missing_mask])\n",
    "  loss.backward()\n",
    "  opt.step()\n",
    "\n",
    "filled_imgs = to_range_0_1(filled_imgs)\n",
    "missing_imgs = to_range_0_1(missing_imgs)\n",
    "input = missing_imgs.detach().clone()\n",
    "input[missing_mask] = 0.2\n",
    "\n",
    "for i in range(n_missing_img):\n",
    "  grid = make_grid(torch.concat([input[[i]], filled_imgs[[i]], missing_imgs[[i]]], dim=0))\n",
    "  fig = show(grid)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "CelebA.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
