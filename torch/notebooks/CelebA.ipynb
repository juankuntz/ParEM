{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juankuntz/ParEM/blob/torch_code/torch/notebooks/CelebA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceG5fAENPfr6"
      },
      "source": [
        "# Import modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLCqb7XBKj2b"
      },
      "outputs": [],
      "source": [
        "# Install missing modules\n",
        "%%capture\n",
        "# Install missing packages\n",
        "!pip install torchtyping\n",
        "!pip install wandb\n",
        "!pip install torchmetrics[image]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpxVMzKzQGaN"
      },
      "outputs": [],
      "source": [
        "# Import standard modules\n",
        "import torch\n",
        "import numpy as np\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "#from pathlib import Path\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X55L4TEtl385"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Import custom modules\n",
        "from pathlib import Path\n",
        "CHECKPOINTS_PATH = Path('/content/gdrive/MyDrive/ParEM/celeba/checkpoints')\n",
        "\n",
        "!rm -rf ParEM\n",
        "!git clone https://github.com/juankuntz/ParEM.git\n",
        "REPOSITORY_PATH = '/content/ParEM/torch'\n",
        "if REPOSITORY_PATH not in sys.path:\n",
        "    sys.path.append(REPOSITORY_PATH)\n",
        "\n",
        "# Import custom modules\n",
        "from parem.models import NLVM\n",
        "from parem.algorithms import (PGA,\n",
        "                              ShortRun,\n",
        "                              VI,\n",
        "                              AlternatingBackprop)\n",
        "from parem.utils import get_celeba, load_checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S7vBXKyCtX3"
      },
      "source": [
        "# Set config variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ssu1R-nnaGpW"
      },
      "outputs": [],
      "source": [
        "# Data setttings\n",
        "N_IMAGES = 10000  # M: training set size \n",
        "\n",
        "# Training settings\n",
        "N_BATCH = 128 # M_b: batch size for theta updates\n",
        "N_EPOCHS = 500 # n_epochs = K * M_b / M where K = total number of iterations\n",
        "SEED = 1 # Seed for PRNG\n",
        "# Device on which to carry out computations:\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "OPTIMIZER = 'rmsprop'  # Theta optimizer\n",
        "\n",
        "# Model Settings\n",
        "X_DIM = 64  # d_x: dimension of latent space\n",
        "LIKELIHOOD_VAR = 0.01 ** 2  # sigma^2\n",
        "\n",
        "# PGA Settings\n",
        "STEP_SIZE = 1e-4 # h: step size \n",
        "LAMBDA = 1e-3 / (STEP_SIZE * N_IMAGES)  # lambda\n",
        "N_PARTICLES = 10 # N: number of particles\n",
        "\n",
        "constants_to_be_logged = {'Number of training images': N_IMAGES, \n",
        "                          'Batch sizes':N_BATCH, \n",
        "                          'PRNG seed': SEED, \n",
        "                          'Latent variable dimension': X_DIM, \n",
        "                          'sigma^2': LIKELIHOOD_VAR,\n",
        "                          'step size': STEP_SIZE, \n",
        "                          'lambda': LAMBDA, \n",
        "                          'Number of particles': N_PARTICLES}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbrwaBFyRb4P"
      },
      "source": [
        "# Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXOewTu5Piuw"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "from pathlib import Path\n",
        "drive.mount(\"/content/gdrive\", force_remount=False)\n",
        "GDRIVE_CELEBA_PATH = Path(\"/content/gdrive/MyDrive/datasets/celeba\")\n",
        "LOCAL_CELEBA_DIR_PATH = Path(\"/content/\") / \"celeba\"\n",
        "assert GDRIVE_CELEBA_PATH.is_dir()\n",
        "if not LOCAL_CELEBA_DIR_PATH.is_dir():\n",
        "  !cp -r $GDRIVE_CELEBA_PATH -d /content/\n",
        "  img_aligned_zip_path = LOCAL_CELEBA_DIR_PATH / \"img_align_celeba.zip\"\n",
        "  !unzip $img_aligned_zip_path -d $LOCAL_CELEBA_DIR_PATH\n",
        "\n",
        "dataset = get_celeba(LOCAL_CELEBA_DIR_PATH / \"img_align_celeba\", N_IMAGES)  # Load dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDZ3YFSSF5zK"
      },
      "source": [
        "# Define and train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "weq8_THjRHw-"
      },
      "outputs": [],
      "source": [
        "# # Define model:\n",
        "model = NLVM(x_dim=X_DIM, sigma2=LIKELIHOOD_VAR, nc=3).to(DEVICE)\n",
        "\n",
        "# Define training algorithm:\n",
        "pga = PGA(model=model, lambd=LAMBDA, dataset=dataset, train_batch_size=N_BATCH,\n",
        "                          particle_step_size=STEP_SIZE, device=DEVICE,\n",
        "                          theta_optimizer=OPTIMIZER)\n",
        "\n",
        "pga.run(N_EPOCHS, CHECKPOINTS_PATH / '/mnist_vae1.pt', compute_stats=False, wandb_log=False, log_images=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oKN0IuLupvF"
      },
      "source": [
        "# Show particle cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "N2uiBWF1KPSu"
      },
      "outputs": [],
      "source": [
        "#@title Load auxiliary functions\n",
        "from torchvision.utils import make_grid\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "to_range_0_1 = lambda x: (x + 1.) / 2.\n",
        "\n",
        "def show(imgs):\n",
        "    if not isinstance(imgs, list):\n",
        "        imgs = [imgs]\n",
        "    fig, axs = plt.subplots(ncols=len(imgs), squeeze=False, dpi=400)\n",
        "    for i, img in enumerate(imgs):\n",
        "        img = img.detach()\n",
        "        img = F.to_pil_image(img)\n",
        "        axs[0, i].imshow(np.asarray(img))\n",
        "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aDBWR0Auv0s"
      },
      "outputs": [],
      "source": [
        "pga.sample_image_posterior(10, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGf5tlEluk-Y"
      },
      "source": [
        "## Generate synthetic samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-rUPIRqugao"
      },
      "outputs": [],
      "source": [
        "pga.synthesize_images(n=64, approx_type='gmm', n_components=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inHFOXauvFAM"
      },
      "source": [
        "## Inpainting "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bF59nI7COLIO"
      },
      "outputs": [],
      "source": [
        "n_missing_img = 20\n",
        "images = torch.stack(dataset[:n_missing_img][0], dim=0)\n",
        "mask = torch.ones(dataset.height, dataset.width, dtype=torch.bool)\n",
        "\n",
        "for i in range(10, 22):\n",
        "  for j in range(10, 22):\n",
        "        mask[i, j] = False\n",
        "\n",
        "pga.reconstruct(images, mask)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UTbBGNxNWjHE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}