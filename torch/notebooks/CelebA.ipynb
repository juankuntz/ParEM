{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/juankuntz/ParEM/blob/main/torch/notebooks/CelebA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceG5fAENPfr6"
   },
   "source": [
    "## Colab setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TLCqb7XBKj2b"
   },
   "outputs": [],
   "source": [
    "# Install missing modules\n",
    "%%capture\n",
    "# Install missing packages\n",
    "!pip install torchtyping\n",
    "!pip install wandb\n",
    "!pip install torchmetrics[image]\n",
    "\n",
    "# Import standard modules\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "#from pathlib import Path\n",
    "from google.colab import drive\n",
    "\n",
    "# Import custom modules\n",
    "from pathlib import Path\n",
    "CHECKPOINTS_PATH = Path('/content/gdrive/MyDrive/ParEM/celeba/checkpoints')\n",
    "\n",
    "!rm -rf ParEM\n",
    "!git clone https://github.com/juankuntz/ParEM.git\n",
    "REPOSITORY_PATH = '/content/ParEM/torch'\n",
    "if REPOSITORY_PATH not in sys.path:\n",
    "    sys.path.append(REPOSITORY_PATH)\n",
    "\n",
    "# Import custom modules\n",
    "from parem.models import NLVM\n",
    "from parem.algorithms import (PGD,\n",
    "                              ShortRun,\n",
    "                              VI,\n",
    "                              AlternatingBackprop)\n",
    "from parem.utils import get_celeba, load_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3S7vBXKyCtX3"
   },
   "source": [
    "# Set config variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ssu1R-nnaGpW"
   },
   "outputs": [],
   "source": [
    "# Data setttings\n",
    "N_IMAGES = 10000  # M: training set size \n",
    "\n",
    "# Training settings\n",
    "N_BATCH = 128 # M_b: batch size for theta updates\n",
    "N_EPOCHS = 500 # n_epochs = K * M_b / M where K = total number of iterations\n",
    "SEED = 1 # Seed for PRNG\n",
    "# Device on which to carry out computations:\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "OPTIMIZER = 'rmsprop'  # Theta optimizer\n",
    "\n",
    "# Model Settings\n",
    "X_DIM = 64  # d_x: dimension of latent space\n",
    "LIKELIHOOD_VAR = 0.01 ** 2  # sigma^2\n",
    "\n",
    "# PGD Settings\n",
    "STEP_SIZE = 1e-4 # h: step size \n",
    "LAMBDA = 1e-3 / (STEP_SIZE * N_IMAGES)  # lambda\n",
    "N_PARTICLES = 10 # N: number of particles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tbrwaBFyRb4P"
   },
   "source": [
    "# Load dataset\n",
    "\n",
    "The dataset *must already be downloaded* in your Google Drive. The location is specfied by the variable `GDRIVE_CELEBA_PATH`. If not please download directly from the [source](https://drive.google.com/drive/folders/0B7EVK8r0v71pTUZsaXdaSnZBZzg?resourcekey=0-rJlzl934LzC-Xp28GeIBzQ). All we need is `img_align_celeba.zip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aXOewTu5Piuw"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from pathlib import Path\n",
    "drive.mount(\"/content/gdrive\", force_remount=False)\n",
    "GDRIVE_CELEBA_PATH = Path(\"/content/gdrive/MyDrive/datasets/celeba\")\n",
    "LOCAL_CELEBA_DIR_PATH = Path(\"/content/\") / \"celeba\"\n",
    "assert GDRIVE_CELEBA_PATH.is_dir()\n",
    "if not LOCAL_CELEBA_DIR_PATH.is_dir():\n",
    "  !cp -r $GDRIVE_CELEBA_PATH -d /content/\n",
    "  img_aligned_zip_path = LOCAL_CELEBA_DIR_PATH / \"img_align_celeba.zip\"\n",
    "  !unzip $img_aligned_zip_path -d $LOCAL_CELEBA_DIR_PATH\n",
    "\n",
    "dataset = get_celeba(LOCAL_CELEBA_DIR_PATH / \"img_align_celeba\", N_IMAGES)  # Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDZ3YFSSF5zK"
   },
   "source": [
    "# Define model and training algorithm\n",
    "\n",
    "The training algorithm selected here is `PGD`. Other algorithms have been implemented in the paper such as:\n",
    "\n",
    "* [Short Run MCMC](https://arxiv.org/abs/1912.01909) using the class called `ShortRun`.\n",
    "* [Variational Inference](https://arxiv.org/pdf/1312.6114.pdf) using the class called `VI`.\n",
    "* [Alternating Backpropagation](https://arxiv.org/abs/1606.08571) using the class called `AlternatingBackprop`.\n",
    "\n",
    "Their interface is similar to `PGD`, this can be seen in `torch/parem/algorithm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "id": "weq8_THjRHw-"
   },
   "outputs": [],
   "source": [
    "# # Define model:\n",
    "model = NLVM(x_dim=X_DIM, sigma2=LIKELIHOOD_VAR, nc=3).to(DEVICE)\n",
    "\n",
    "# Define training algorithm:\n",
    "pgd = PGD(model=model, lambd=LAMBDA, dataset=dataset, train_batch_size=N_BATCH,\n",
    "                          particle_step_size=STEP_SIZE, device=DEVICE,\n",
    "                          theta_optimizer=OPTIMIZER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "\n",
    "Calling `{PGD , VI, AlternatingBackprop, ShortRun}.run(...)` will train the model. Using the options, we can have more transparency about the progress during training\n",
    "* `wandb_log`: Using [Weights and Biases](https://wandb.ai/site) to log the training.\n",
    "* `log_images`: Logged images using [Weights and Biases](https://wandb.ai/site).\n",
    "* `compute_stats`: Compute FID, and MSE during training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgd.run(N_EPOCHS, CHECKPOINTS_PATH / '/celeba_vae1.pt', compute_stats=False, wandb_log=False, log_images=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oKN0IuLupvF"
   },
   "source": [
    "# Show particle cloud\n",
    "\n",
    "Calling `{PGD , VI, AlternatingBackprop, ShortRun}.sample_image_posterior(...)` will be able to view the image that corresponds to the latent variable of an image from the training dataset. The first argument is the index of the training image and the second the number of particles to visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0aDBWR0Auv0s"
   },
   "outputs": [],
   "source": [
    "pgd.sample_image_posterior(10, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGf5tlEluk-Y"
   },
   "source": [
    "# Generate synthetic samples\n",
    "\n",
    "Generate samples from the model using `{PGD , VI, AlternatingBackprop, ShortRun}.synthesize_images(...)`. The optional argument `approx_type` specifies the approximation used on the posterior. If\n",
    "* `approx_type` is `gmm`. A Gaussian Mixture distribution is used, and `n_components` option specifies the number of components.\n",
    "* `approx_type` is `gaussian`. A Gaussian distribution is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-rUPIRqugao"
   },
   "outputs": [],
   "source": [
    "pgd.synthesize_images(n=64, approx_type='gmm', n_components=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inHFOXauvFAM"
   },
   "source": [
    "# Inpainting\n",
    "Calling `{PGD , VI, AlternatingBackprop, ShortRun}.reconstruct(img, mask=None)` will retrun the reconstruction of `img`. If `mask` is not `None`, then a partially occluded image is passed in and the result can be used to impute the missing pixels specified by the `mask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bF59nI7COLIO"
   },
   "outputs": [],
   "source": [
    "n_missing_img = 20\n",
    "images = torch.stack(dataset[:n_missing_img][0], dim=0)\n",
    "mask = torch.ones(dataset.height, dataset.width, dtype=torch.bool)\n",
    "\n",
    "for i in range(10, 22):\n",
    "    for j in range(10, 22):\n",
    "        mask[i, j] = False\n",
    "\n",
    "pgd.reconstruct(images, mask)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
