{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/juankuntz/ParEM/blob/main/torch/notebooks/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ELgDUrII6Ln"
   },
   "source": [
    "## Colab setup\n",
    "\n",
    "Installs and imports the necessary modules. Variables of interest:\n",
    "\n",
    "* `DATASET_PATH`: The directory of the dataset to be loaded or downloaded.\n",
    "* `CHECKPOINTS_PATH`: The directory where the checkpoints will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TLCqb7XBKj2b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Set paths\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\", force_remount=False) # Mount drive to VM in colab\n",
    "DATASET_PATH = '/content/ParEM/datasets/MNIST'\n",
    "CHECKPOINTS_PATH = '/content/gdrive/MyDrive/ParEM/checkpoints'\n",
    "\n",
    "# Install missing packages\n",
    "!pip install torchtyping\n",
    "!pip install torchmetrics[image]\n",
    "!pip install wandb\n",
    "\n",
    "# Import standard modules\n",
    "import sys\n",
    "\n",
    "# Import custom modules\n",
    "!rm -rf ParEM\n",
    "!git clone https://github.com/juankuntz/ParEM.git\n",
    "REPOSITORY_PATH = '/content/ParEM/torch'\n",
    "if REPOSITORY_PATH not in sys.path:\n",
    "    sys.path.append(REPOSITORY_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdeY8MWzI6Lq"
   },
   "source": [
    "## General setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HhHKhq7tI6Lq"
   },
   "outputs": [],
   "source": [
    "# Import standard modules\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Import custom modules\n",
    "from parem.models import NLVM\n",
    "from parem.algorithms import (PGD,\n",
    "                              ShortRun,\n",
    "                              VI,\n",
    "                              AlternatingBackprop)\n",
    "from parem.utils import get_mnist, load_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3S7vBXKyCtX3"
   },
   "source": [
    "# Set config variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ssu1R-nnaGpW"
   },
   "outputs": [],
   "source": [
    "# Data setttings\n",
    "N_IMAGES = 10000  # M: training set size \n",
    "\n",
    "# Training settings\n",
    "N_BATCH = 128 # M_b: batch size for theta updates\n",
    "N_EPOCHS = 100 # n_epochs = K * M_b / M where K = total number of iterations\n",
    "SEED = 1 # Seed for PRNG\n",
    "# Device on which to carry out computations:\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "OPTIMIZER = 'rmsprop'  # Theta optimizer\n",
    "\n",
    "# Model Settings\n",
    "X_DIM = 64  # d_x: dimension of latent space\n",
    "LIKELIHOOD_VAR = 0.01 ** 2  # sigma^2\n",
    "\n",
    "# PGD Settings\n",
    "STEP_SIZE = 1e-4 # h: step size \n",
    "LAMBDA = 1e-3 / (STEP_SIZE * N_IMAGES)  # lambda\n",
    "N_PARTICLES = 10 # N: number of particles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tbrwaBFyRb4P"
   },
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aXOewTu5Piuw"
   },
   "outputs": [],
   "source": [
    "mnist = get_mnist(DATASET_PATH, N_IMAGES)  # Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDZ3YFSSF5zK"
   },
   "source": [
    "# Define model and training algorithm\n",
    "\n",
    "The training algorithm selected here is `PGD`. Other algorithms have been implemented in the paper such as:\n",
    "\n",
    "* [Short Run MCMC](https://arxiv.org/abs/1912.01909) using the class called `ShortRun`.\n",
    "* [Variational Inference](https://arxiv.org/pdf/1312.6114.pdf) using the class called `VI`.\n",
    "* [Alternating Backpropagation](https://arxiv.org/abs/1606.08571) using the class called `AlternatingBackprop`.\n",
    "\n",
    "Their interface is similar to `PGD`, this can be seen in `torch/parem/algorithm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TKsiYi21Falp"
   },
   "outputs": [],
   "source": [
    "# Define model:\n",
    "model = NLVM(x_dim=X_DIM, sigma2=LIKELIHOOD_VAR, nc=1).to(DEVICE)\n",
    "\n",
    "# Define training algorithm:\n",
    "pgd = PGD(model=model,\n",
    "          dataset=mnist,\n",
    "          train_batch_size=N_BATCH,\n",
    "          lambd=LAMBDA,\n",
    "          n_particles=N_PARTICLES,\n",
    "          particle_step_size=STEP_SIZE,\n",
    "          device=DEVICE,\n",
    "          theta_optimizer=OPTIMIZER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2CxOMNBFjLY"
   },
   "source": [
    "# Train\n",
    "\n",
    "Calling `{PGD , VI, AlternatingBackprop, ShortRun}.run(...)` will train the model. Using the options, we can have more transparency about the progress during training\n",
    "* `wandb_log`: Using [Weights and Biases](https://wandb.ai/site) to log the training.\n",
    "* `log_images`: Logged images using [Weights and Biases](https://wandb.ai/site).\n",
    "* `compute_stats`: Compute FID, and MSE during training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "id": "weq8_THjRHw-"
   },
   "outputs": [],
   "source": [
    "# Train:\n",
    "pgd.run(N_EPOCHS,\n",
    "        CHECKPOINTS_PATH + '/mnist_small_batchother.pt',\n",
    "        wandb_log=False,\n",
    "        log_images=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oKN0IuLupvF"
   },
   "source": [
    "# Show particle cloud\n",
    "\n",
    "Calling `{PGD , VI, AlternatingBackprop, ShortRun}.sample_image_posterior(...)` will be able to view the image that corresponds to the latent variable of an image from the training dataset. The first argument is the index of the training image and the second the number of particles to visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "N2uiBWF1KPSu"
   },
   "outputs": [],
   "source": [
    "pgd.sample_image_posterior(10, N_PARTICLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inHFOXauvFAM"
   },
   "source": [
    "# Inpainting \n",
    "\n",
    "Calling `{PGD , VI, AlternatingBackprop, ShortRun}.reconstruct(img, mask=None)` will retrun the reconstruction of `img`. If `mask` is not `None`, then a partially occluded image is passed in and the result can be used to impute the missing pixels specified by the `mask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bF59nI7COLIO"
   },
   "outputs": [],
   "source": [
    "n_missing_img = 20\n",
    "images = mnist[:n_missing_img][0]\n",
    "mask = torch.ones(mnist.height, mnist.width, dtype=torch.bool)\n",
    "\n",
    "for i in range(10, 22):\n",
    "    for j in range(10, 22):\n",
    "        mask[i, j] = False\n",
    "\n",
    "pgd.reconstruct(images, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGf5tlEluk-Y"
   },
   "source": [
    "# Generate synthetic samples\n",
    "\n",
    "Generate samples from the model using `{PGD , VI, AlternatingBackprop, ShortRun}.synthesize_images(...)`. The optional argument `approx_type` specifies the approximation used on the posterior. If\n",
    "* `approx_type` is `gmm`. A Gaussian Mixture distribution is used, and `n_components` option specifies the number of components.\n",
    "* `approx_type` is `gaussian`. A Gaussian distribution is used.\n",
    "* `approx_type` is `gaussian_mixture_labels`. A Gaussian distribution is fitted to each class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-rUPIRqugao"
   },
   "outputs": [],
   "source": [
    "pgd.synthesize_images(n=64, approx_type='gmm', n_components=100)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Copy of MNIST.ipynb",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
