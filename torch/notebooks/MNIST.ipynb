{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/juankuntz/ParEM/blob/main/torch/notebooks/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceG5fAENPfr6",
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ELgDUrII6Ln"
   },
   "source": [
    "## Colab setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TLCqb7XBKj2b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Set paths\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\", force_remount=False) # Mount drive to VM in colab\n",
    "DATASET_PATH = '/content/ParEM_neural_latent_variable_model_dev/datasets/MNIST'\n",
    "CHECKPOINTS_PATH = '/content/gdrive/MyDrive/ParEM_neural_latent_variable_model_dev/checkpoints'\n",
    "\n",
    "# Install missing packages\n",
    "!pip install torchtyping\n",
    "!pip install torchmetrics\n",
    "!pip install wandb\n",
    "\n",
    "# Import standard modules\n",
    "import sys\n",
    "\n",
    "# Import custom modules\n",
    "!rm -rf ParEM\n",
    "!git clone https://github.com/juankuntz/ParEM.git\n",
    "!cd ParEM; git checkout torch_code\n",
    "REPOSITORY_PATH = '/content/ParEM/torch'\n",
    "if REPOSITORY_PATH not in sys.path:\n",
    "    sys.path.append(REPOSITORY_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdeY8MWzI6Lq"
   },
   "source": [
    "## General setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HhHKhq7tI6Lq"
   },
   "outputs": [],
   "source": [
    "# Import standard modules\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Import custom modules\n",
    "from parem.models import NLVM\n",
    "from parem.algorithms import PGD\n",
    "from parem.utils import get_mnist, load_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3S7vBXKyCtX3"
   },
   "source": [
    "# Set config variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ssu1R-nnaGpW"
   },
   "outputs": [],
   "source": [
    "# Data setttings\n",
    "N_IMAGES = 10000  # M: training set size \n",
    "\n",
    "# Training settings\n",
    "N_BATCH = 128 # M_b: batch size for theta updates\n",
    "N_EPOCHS = 100 # n_epochs = K * M_b / M where K = total number of iterations\n",
    "SEED = 1 # Seed for PRNG\n",
    "# Device on which to carry out computations:\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "OPTIMIZER = 'rmsprop'  # Theta optimizer\n",
    "\n",
    "# Model Settings\n",
    "X_DIM = 64  # d_x: dimension of latent space\n",
    "LIKELIHOOD_VAR = 0.01 ** 2  # sigma^2\n",
    "\n",
    "# PGD Settings\n",
    "STEP_SIZE = 1e-4 # h: step size \n",
    "LAMBDA = 1e-3 / (STEP_SIZE * N_IMAGES)  # lambda\n",
    "N_PARTICLES = 10 # N: number of particles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tbrwaBFyRb4P"
   },
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aXOewTu5Piuw"
   },
   "outputs": [],
   "source": [
    "mnist = get_mnist(DATASET_PATH, N_IMAGES)  # Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDZ3YFSSF5zK"
   },
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TKsiYi21Falp"
   },
   "outputs": [],
   "source": [
    "# Define model:\n",
    "model = NLVM(x_dim=X_DIM, sigma2=LIKELIHOOD_VAR, nc=1).to(DEVICE)\n",
    "\n",
    "# Define training algorithm:\n",
    "pgd = PGD(model=model, dataset=mnist, train_batch_size=N_BATCH, lambd=LAMBDA,\n",
    "          n_particles=N_PARTICLES, particle_step_size=STEP_SIZE, device=DEVICE,\n",
    "          theta_optimizer=OPTIMIZER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssHdP1QEFcfx"
   },
   "source": [
    "# Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OkJTPkNOFcG0"
   },
   "outputs": [],
   "source": [
    "#  pgd = load_checkpoint(CHECKPOINTS_PATH + '/mnist_working.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2CxOMNBFjLY"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "id": "weq8_THjRHw-"
   },
   "outputs": [],
   "source": [
    "# Train:\n",
    "pgd.run(N_EPOCHS, CHECKPOINTS_PATH + '/mnist_small_batchother.pt',\n",
    "        wandb_log=False, log_images=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oKN0IuLupvF"
   },
   "source": [
    "# Show particle cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "N2uiBWF1KPSu"
   },
   "outputs": [],
   "source": [
    "pgd.sample_image_posterior(10, N_PARTICLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inHFOXauvFAM"
   },
   "source": [
    "## Inpainting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bF59nI7COLIO"
   },
   "outputs": [],
   "source": [
    "n_missing_img = 20\n",
    "images = mnist[:n_missing_img][0]\n",
    "mask = torch.ones(mnist.height, mnist.width, dtype=torch.bool)\n",
    "\n",
    "for i in range(10, 22):\n",
    "  for j in range(10, 22):\n",
    "        mask[i, j] = False\n",
    "\n",
    "pgd.reconstruct(images, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGf5tlEluk-Y"
   },
   "source": [
    "## Generate synthetic samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-rUPIRqugao"
   },
   "outputs": [],
   "source": [
    "pgd.synthesize_images(n=64, approx_type='gmm', n_components=3)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Copy of MNIST.ipynb",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
